{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab:  Logistic Regression for Gene Expression Data\n",
    "\n",
    "In this lab, we use logistic regression to predict biological characteristics (\"phenotypes\") from gene expression data.  In addition to the concepts in [breast cancer demo](./breast_cancer.ipynb), you will learn to:\n",
    "* Handle missing data\n",
    "* Perform multi-class logistic classification\n",
    "* Create a confusion matrix\n",
    "* Use L1-regularization for improved estimation in the case of sparse weights (Grad students only)\n",
    "\n",
    "## Background\n",
    "\n",
    "Genes are the basic unit in the DNA and encode blueprints for proteins.  When proteins are synthesized from a gene, the gene is said to \"express\".  Micro-arrays are devices that measure the expression levels of large numbers of genes in parallel.  By finding correlations between expression levels and phenotypes, scientists can identify possible genetic markers for biological characteristics.\n",
    "\n",
    "The data in this lab comes from:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression\n",
    "\n",
    "In this data, mice were characterized by three properties:\n",
    "* Whether they had down's syndrome (trisomy) or not\n",
    "* Whether they were stimulated to learn or not\n",
    "* Whether they had a drug memantine or a saline control solution.\n",
    "\n",
    "With these three choices, there are 8 possible classes for each mouse.  For each mouse, the expression levels were measured across 77 genes.  We will see if the characteristics can be predicted from the gene expression levels.  This classification could reveal which genes are potentially involved in Down's syndrome and if drugs and learning have any noticeable effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We begin by loading the standard modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `pd.read_excel` command to read the data from \n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls\n",
    "\n",
    "into a dataframe `df`.  Use the `index_col` option to specify that column 0 is the index.  Use the `df.head()` to print the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xlrd >= 1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYRK1A_N</th>\n",
       "      <th>ITSN1_N</th>\n",
       "      <th>BDNF_N</th>\n",
       "      <th>NR1_N</th>\n",
       "      <th>NR2A_N</th>\n",
       "      <th>pAKT_N</th>\n",
       "      <th>pBRAF_N</th>\n",
       "      <th>pCAMKII_N</th>\n",
       "      <th>pCREB_N</th>\n",
       "      <th>pELK_N</th>\n",
       "      <th>...</th>\n",
       "      <th>pCFOS_N</th>\n",
       "      <th>SYP_N</th>\n",
       "      <th>H3AcK18_N</th>\n",
       "      <th>EGR1_N</th>\n",
       "      <th>H3MeK4_N</th>\n",
       "      <th>CaNA_N</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MouseID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309_1</th>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.747193</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>2.816329</td>\n",
       "      <td>5.990152</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>0.177565</td>\n",
       "      <td>2.373744</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>1.750936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108336</td>\n",
       "      <td>0.427099</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>0.131790</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>1.675652</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_2</th>\n",
       "      <td>0.514617</td>\n",
       "      <td>0.689064</td>\n",
       "      <td>0.411770</td>\n",
       "      <td>2.789514</td>\n",
       "      <td>5.685038</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.172817</td>\n",
       "      <td>2.292150</td>\n",
       "      <td>0.226972</td>\n",
       "      <td>1.596377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.441581</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>1.743610</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_3</th>\n",
       "      <td>0.509183</td>\n",
       "      <td>0.730247</td>\n",
       "      <td>0.418309</td>\n",
       "      <td>2.687201</td>\n",
       "      <td>5.622059</td>\n",
       "      <td>0.209011</td>\n",
       "      <td>0.175722</td>\n",
       "      <td>2.283337</td>\n",
       "      <td>0.230247</td>\n",
       "      <td>1.561316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106219</td>\n",
       "      <td>0.435777</td>\n",
       "      <td>0.111883</td>\n",
       "      <td>0.133362</td>\n",
       "      <td>0.127431</td>\n",
       "      <td>1.926427</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_4</th>\n",
       "      <td>0.442107</td>\n",
       "      <td>0.617076</td>\n",
       "      <td>0.358626</td>\n",
       "      <td>2.466947</td>\n",
       "      <td>4.979503</td>\n",
       "      <td>0.222886</td>\n",
       "      <td>0.176463</td>\n",
       "      <td>2.152301</td>\n",
       "      <td>0.207004</td>\n",
       "      <td>1.595086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111262</td>\n",
       "      <td>0.391691</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.147444</td>\n",
       "      <td>0.146901</td>\n",
       "      <td>1.700563</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_5</th>\n",
       "      <td>0.434940</td>\n",
       "      <td>0.617430</td>\n",
       "      <td>0.358802</td>\n",
       "      <td>2.365785</td>\n",
       "      <td>4.718679</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>0.173627</td>\n",
       "      <td>2.134014</td>\n",
       "      <td>0.192158</td>\n",
       "      <td>1.504230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110694</td>\n",
       "      <td>0.434154</td>\n",
       "      <td>0.118481</td>\n",
       "      <td>0.140314</td>\n",
       "      <td>0.148380</td>\n",
       "      <td>1.839730</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
       "MouseID                                                                         \n",
       "309_1    0.503644  0.747193  0.430175  2.816329  5.990152  0.218830  0.177565   \n",
       "309_2    0.514617  0.689064  0.411770  2.789514  5.685038  0.211636  0.172817   \n",
       "309_3    0.509183  0.730247  0.418309  2.687201  5.622059  0.209011  0.175722   \n",
       "309_4    0.442107  0.617076  0.358626  2.466947  4.979503  0.222886  0.176463   \n",
       "309_5    0.434940  0.617430  0.358802  2.365785  4.718679  0.213106  0.173627   \n",
       "\n",
       "         pCAMKII_N   pCREB_N    pELK_N  ...   pCFOS_N     SYP_N  H3AcK18_N  \\\n",
       "MouseID                                 ...                                  \n",
       "309_1     2.373744  0.232224  1.750936  ...  0.108336  0.427099   0.114783   \n",
       "309_2     2.292150  0.226972  1.596377  ...  0.104315  0.441581   0.111974   \n",
       "309_3     2.283337  0.230247  1.561316  ...  0.106219  0.435777   0.111883   \n",
       "309_4     2.152301  0.207004  1.595086  ...  0.111262  0.391691   0.130405   \n",
       "309_5     2.134014  0.192158  1.504230  ...  0.110694  0.434154   0.118481   \n",
       "\n",
       "           EGR1_N  H3MeK4_N    CaNA_N  Genotype  Treatment  Behavior   class  \n",
       "MouseID                                                                       \n",
       "309_1    0.131790  0.128186  1.675652   Control  Memantine       C/S  c-CS-m  \n",
       "309_2    0.135103  0.131119  1.743610   Control  Memantine       C/S  c-CS-m  \n",
       "309_3    0.133362  0.127431  1.926427   Control  Memantine       C/S  c-CS-m  \n",
       "309_4    0.147444  0.146901  1.700563   Control  Memantine       C/S  c-CS-m  \n",
       "309_5    0.140314  0.148380  1.839730   Control  Memantine       C/S  c-CS-m  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "df = pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls',\n",
    "                   index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has missing values.  The site:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
    "\n",
    "has an excellent summary of methods to deal with missing values.  Following the techniques there, create a new data frame `df1` where the missing values in each column are filled with the mean values from the non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1080 entries, 309_1 to J3295_15\n",
      "Data columns (total 81 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   DYRK1A_N         1077 non-null   float64\n",
      " 1   ITSN1_N          1077 non-null   float64\n",
      " 2   BDNF_N           1077 non-null   float64\n",
      " 3   NR1_N            1077 non-null   float64\n",
      " 4   NR2A_N           1077 non-null   float64\n",
      " 5   pAKT_N           1077 non-null   float64\n",
      " 6   pBRAF_N          1077 non-null   float64\n",
      " 7   pCAMKII_N        1077 non-null   float64\n",
      " 8   pCREB_N          1077 non-null   float64\n",
      " 9   pELK_N           1077 non-null   float64\n",
      " 10  pERK_N           1077 non-null   float64\n",
      " 11  pJNK_N           1077 non-null   float64\n",
      " 12  PKCA_N           1077 non-null   float64\n",
      " 13  pMEK_N           1077 non-null   float64\n",
      " 14  pNR1_N           1077 non-null   float64\n",
      " 15  pNR2A_N          1077 non-null   float64\n",
      " 16  pNR2B_N          1077 non-null   float64\n",
      " 17  pPKCAB_N         1077 non-null   float64\n",
      " 18  pRSK_N           1077 non-null   float64\n",
      " 19  AKT_N            1077 non-null   float64\n",
      " 20  BRAF_N           1077 non-null   float64\n",
      " 21  CAMKII_N         1077 non-null   float64\n",
      " 22  CREB_N           1077 non-null   float64\n",
      " 23  ELK_N            1062 non-null   float64\n",
      " 24  ERK_N            1077 non-null   float64\n",
      " 25  GSK3B_N          1077 non-null   float64\n",
      " 26  JNK_N            1077 non-null   float64\n",
      " 27  MEK_N            1073 non-null   float64\n",
      " 28  TRKA_N           1077 non-null   float64\n",
      " 29  RSK_N            1077 non-null   float64\n",
      " 30  APP_N            1077 non-null   float64\n",
      " 31  Bcatenin_N       1062 non-null   float64\n",
      " 32  SOD1_N           1077 non-null   float64\n",
      " 33  MTOR_N           1077 non-null   float64\n",
      " 34  P38_N            1077 non-null   float64\n",
      " 35  pMTOR_N          1077 non-null   float64\n",
      " 36  DSCR1_N          1077 non-null   float64\n",
      " 37  AMPKA_N          1077 non-null   float64\n",
      " 38  NR2B_N           1077 non-null   float64\n",
      " 39  pNUMB_N          1077 non-null   float64\n",
      " 40  RAPTOR_N         1077 non-null   float64\n",
      " 41  TIAM1_N          1077 non-null   float64\n",
      " 42  pP70S6_N         1077 non-null   float64\n",
      " 43  NUMB_N           1080 non-null   float64\n",
      " 44  P70S6_N          1080 non-null   float64\n",
      " 45  pGSK3B_N         1080 non-null   float64\n",
      " 46  pPKCG_N          1080 non-null   float64\n",
      " 47  CDK5_N           1080 non-null   float64\n",
      " 48  S6_N             1080 non-null   float64\n",
      " 49  ADARB1_N         1080 non-null   float64\n",
      " 50  AcetylH3K9_N     1080 non-null   float64\n",
      " 51  RRP1_N           1080 non-null   float64\n",
      " 52  BAX_N            1080 non-null   float64\n",
      " 53  ARC_N            1080 non-null   float64\n",
      " 54  ERBB4_N          1080 non-null   float64\n",
      " 55  nNOS_N           1080 non-null   float64\n",
      " 56  Tau_N            1080 non-null   float64\n",
      " 57  GFAP_N           1080 non-null   float64\n",
      " 58  GluR3_N          1080 non-null   float64\n",
      " 59  GluR4_N          1080 non-null   float64\n",
      " 60  IL1B_N           1080 non-null   float64\n",
      " 61  P3525_N          1080 non-null   float64\n",
      " 62  pCASP9_N         1080 non-null   float64\n",
      " 63  PSD95_N          1080 non-null   float64\n",
      " 64  SNCA_N           1080 non-null   float64\n",
      " 65  Ubiquitin_N      1080 non-null   float64\n",
      " 66  pGSK3B_Tyr216_N  1080 non-null   float64\n",
      " 67  SHH_N            1080 non-null   float64\n",
      " 68  BAD_N            867 non-null    float64\n",
      " 69  BCL2_N           795 non-null    float64\n",
      " 70  pS6_N            1080 non-null   float64\n",
      " 71  pCFOS_N          1005 non-null   float64\n",
      " 72  SYP_N            1080 non-null   float64\n",
      " 73  H3AcK18_N        900 non-null    float64\n",
      " 74  EGR1_N           870 non-null    float64\n",
      " 75  H3MeK4_N         810 non-null    float64\n",
      " 76  CaNA_N           1080 non-null   float64\n",
      " 77  Genotype         1080 non-null   object \n",
      " 78  Treatment        1080 non-null   object \n",
      " 79  Behavior         1080 non-null   object \n",
      " 80  class            1080 non-null   object \n",
      "dtypes: float64(77), object(4)\n",
      "memory usage: 691.9+ KB\n"
     ]
    }
   ],
   "source": [
    " # show if there are missing values and columns data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1080 entries, 309_1 to J3295_15\n",
      "Data columns (total 81 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   DYRK1A_N         1080 non-null   float64\n",
      " 1   ITSN1_N          1080 non-null   float64\n",
      " 2   BDNF_N           1080 non-null   float64\n",
      " 3   NR1_N            1080 non-null   float64\n",
      " 4   NR2A_N           1080 non-null   float64\n",
      " 5   pAKT_N           1080 non-null   float64\n",
      " 6   pBRAF_N          1080 non-null   float64\n",
      " 7   pCAMKII_N        1080 non-null   float64\n",
      " 8   pCREB_N          1080 non-null   float64\n",
      " 9   pELK_N           1080 non-null   float64\n",
      " 10  pERK_N           1080 non-null   float64\n",
      " 11  pJNK_N           1080 non-null   float64\n",
      " 12  PKCA_N           1080 non-null   float64\n",
      " 13  pMEK_N           1080 non-null   float64\n",
      " 14  pNR1_N           1080 non-null   float64\n",
      " 15  pNR2A_N          1080 non-null   float64\n",
      " 16  pNR2B_N          1080 non-null   float64\n",
      " 17  pPKCAB_N         1080 non-null   float64\n",
      " 18  pRSK_N           1080 non-null   float64\n",
      " 19  AKT_N            1080 non-null   float64\n",
      " 20  BRAF_N           1080 non-null   float64\n",
      " 21  CAMKII_N         1080 non-null   float64\n",
      " 22  CREB_N           1080 non-null   float64\n",
      " 23  ELK_N            1080 non-null   float64\n",
      " 24  ERK_N            1080 non-null   float64\n",
      " 25  GSK3B_N          1080 non-null   float64\n",
      " 26  JNK_N            1080 non-null   float64\n",
      " 27  MEK_N            1080 non-null   float64\n",
      " 28  TRKA_N           1080 non-null   float64\n",
      " 29  RSK_N            1080 non-null   float64\n",
      " 30  APP_N            1080 non-null   float64\n",
      " 31  Bcatenin_N       1080 non-null   float64\n",
      " 32  SOD1_N           1080 non-null   float64\n",
      " 33  MTOR_N           1080 non-null   float64\n",
      " 34  P38_N            1080 non-null   float64\n",
      " 35  pMTOR_N          1080 non-null   float64\n",
      " 36  DSCR1_N          1080 non-null   float64\n",
      " 37  AMPKA_N          1080 non-null   float64\n",
      " 38  NR2B_N           1080 non-null   float64\n",
      " 39  pNUMB_N          1080 non-null   float64\n",
      " 40  RAPTOR_N         1080 non-null   float64\n",
      " 41  TIAM1_N          1080 non-null   float64\n",
      " 42  pP70S6_N         1080 non-null   float64\n",
      " 43  NUMB_N           1080 non-null   float64\n",
      " 44  P70S6_N          1080 non-null   float64\n",
      " 45  pGSK3B_N         1080 non-null   float64\n",
      " 46  pPKCG_N          1080 non-null   float64\n",
      " 47  CDK5_N           1080 non-null   float64\n",
      " 48  S6_N             1080 non-null   float64\n",
      " 49  ADARB1_N         1080 non-null   float64\n",
      " 50  AcetylH3K9_N     1080 non-null   float64\n",
      " 51  RRP1_N           1080 non-null   float64\n",
      " 52  BAX_N            1080 non-null   float64\n",
      " 53  ARC_N            1080 non-null   float64\n",
      " 54  ERBB4_N          1080 non-null   float64\n",
      " 55  nNOS_N           1080 non-null   float64\n",
      " 56  Tau_N            1080 non-null   float64\n",
      " 57  GFAP_N           1080 non-null   float64\n",
      " 58  GluR3_N          1080 non-null   float64\n",
      " 59  GluR4_N          1080 non-null   float64\n",
      " 60  IL1B_N           1080 non-null   float64\n",
      " 61  P3525_N          1080 non-null   float64\n",
      " 62  pCASP9_N         1080 non-null   float64\n",
      " 63  PSD95_N          1080 non-null   float64\n",
      " 64  SNCA_N           1080 non-null   float64\n",
      " 65  Ubiquitin_N      1080 non-null   float64\n",
      " 66  pGSK3B_Tyr216_N  1080 non-null   float64\n",
      " 67  SHH_N            1080 non-null   float64\n",
      " 68  BAD_N            1080 non-null   float64\n",
      " 69  BCL2_N           1080 non-null   float64\n",
      " 70  pS6_N            1080 non-null   float64\n",
      " 71  pCFOS_N          1080 non-null   float64\n",
      " 72  SYP_N            1080 non-null   float64\n",
      " 73  H3AcK18_N        1080 non-null   float64\n",
      " 74  EGR1_N           1080 non-null   float64\n",
      " 75  H3MeK4_N         1080 non-null   float64\n",
      " 76  CaNA_N           1080 non-null   float64\n",
      " 77  Genotype         1080 non-null   object \n",
      " 78  Treatment        1080 non-null   object \n",
      " 79  Behavior         1080 non-null   object \n",
      " 80  class            1080 non-null   object \n",
      "dtypes: float64(77), object(4)\n",
      "memory usage: 691.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df1 = df.fillna(df.mean())\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification for Down's Syndrome\n",
    "\n",
    "We will first predict the binary class label in `df1['Genotype']` which indicates if the mouse has Down's syndrome or not.  Get the string values in `df1['Genotype'].values` and convert this to a numeric vector `y` with 0 or 1.  You may wish to use the `np.unique` command with the `return_inverse=True` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "y = df1['Genotype'].values\n",
    "# extract the encoding of categorical data\n",
    "y_class, y = np.unique(y, return_inverse=True)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predictors, get all but the last four columns of the dataframes.  Store the data matrix into `X` and the names of the columns in `xnames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYRK1A_N</th>\n",
       "      <th>ITSN1_N</th>\n",
       "      <th>BDNF_N</th>\n",
       "      <th>NR1_N</th>\n",
       "      <th>NR2A_N</th>\n",
       "      <th>pAKT_N</th>\n",
       "      <th>pBRAF_N</th>\n",
       "      <th>pCAMKII_N</th>\n",
       "      <th>pCREB_N</th>\n",
       "      <th>pELK_N</th>\n",
       "      <th>...</th>\n",
       "      <th>SHH_N</th>\n",
       "      <th>BAD_N</th>\n",
       "      <th>BCL2_N</th>\n",
       "      <th>pS6_N</th>\n",
       "      <th>pCFOS_N</th>\n",
       "      <th>SYP_N</th>\n",
       "      <th>H3AcK18_N</th>\n",
       "      <th>EGR1_N</th>\n",
       "      <th>H3MeK4_N</th>\n",
       "      <th>CaNA_N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MouseID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309_1</th>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.747193</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>2.816329</td>\n",
       "      <td>5.990152</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>0.177565</td>\n",
       "      <td>2.373744</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>1.750936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188852</td>\n",
       "      <td>0.122652</td>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.106305</td>\n",
       "      <td>0.108336</td>\n",
       "      <td>0.427099</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>0.131790</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>1.675652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_2</th>\n",
       "      <td>0.514617</td>\n",
       "      <td>0.689064</td>\n",
       "      <td>0.411770</td>\n",
       "      <td>2.789514</td>\n",
       "      <td>5.685038</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.172817</td>\n",
       "      <td>2.292150</td>\n",
       "      <td>0.226972</td>\n",
       "      <td>1.596377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200404</td>\n",
       "      <td>0.116682</td>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.106592</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.441581</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>1.743610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_3</th>\n",
       "      <td>0.509183</td>\n",
       "      <td>0.730247</td>\n",
       "      <td>0.418309</td>\n",
       "      <td>2.687201</td>\n",
       "      <td>5.622059</td>\n",
       "      <td>0.209011</td>\n",
       "      <td>0.175722</td>\n",
       "      <td>2.283337</td>\n",
       "      <td>0.230247</td>\n",
       "      <td>1.561316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193685</td>\n",
       "      <td>0.118508</td>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.108303</td>\n",
       "      <td>0.106219</td>\n",
       "      <td>0.435777</td>\n",
       "      <td>0.111883</td>\n",
       "      <td>0.133362</td>\n",
       "      <td>0.127431</td>\n",
       "      <td>1.926427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_4</th>\n",
       "      <td>0.442107</td>\n",
       "      <td>0.617076</td>\n",
       "      <td>0.358626</td>\n",
       "      <td>2.466947</td>\n",
       "      <td>4.979503</td>\n",
       "      <td>0.222886</td>\n",
       "      <td>0.176463</td>\n",
       "      <td>2.152301</td>\n",
       "      <td>0.207004</td>\n",
       "      <td>1.595086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192112</td>\n",
       "      <td>0.132781</td>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.103184</td>\n",
       "      <td>0.111262</td>\n",
       "      <td>0.391691</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.147444</td>\n",
       "      <td>0.146901</td>\n",
       "      <td>1.700563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_5</th>\n",
       "      <td>0.434940</td>\n",
       "      <td>0.617430</td>\n",
       "      <td>0.358802</td>\n",
       "      <td>2.365785</td>\n",
       "      <td>4.718679</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>0.173627</td>\n",
       "      <td>2.134014</td>\n",
       "      <td>0.192158</td>\n",
       "      <td>1.504230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205604</td>\n",
       "      <td>0.129954</td>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.104784</td>\n",
       "      <td>0.110694</td>\n",
       "      <td>0.434154</td>\n",
       "      <td>0.118481</td>\n",
       "      <td>0.140314</td>\n",
       "      <td>0.148380</td>\n",
       "      <td>1.839730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
       "MouseID                                                                         \n",
       "309_1    0.503644  0.747193  0.430175  2.816329  5.990152  0.218830  0.177565   \n",
       "309_2    0.514617  0.689064  0.411770  2.789514  5.685038  0.211636  0.172817   \n",
       "309_3    0.509183  0.730247  0.418309  2.687201  5.622059  0.209011  0.175722   \n",
       "309_4    0.442107  0.617076  0.358626  2.466947  4.979503  0.222886  0.176463   \n",
       "309_5    0.434940  0.617430  0.358802  2.365785  4.718679  0.213106  0.173627   \n",
       "\n",
       "         pCAMKII_N   pCREB_N    pELK_N  ...     SHH_N     BAD_N    BCL2_N  \\\n",
       "MouseID                                 ...                                 \n",
       "309_1     2.373744  0.232224  1.750936  ...  0.188852  0.122652  0.134762   \n",
       "309_2     2.292150  0.226972  1.596377  ...  0.200404  0.116682  0.134762   \n",
       "309_3     2.283337  0.230247  1.561316  ...  0.193685  0.118508  0.134762   \n",
       "309_4     2.152301  0.207004  1.595086  ...  0.192112  0.132781  0.134762   \n",
       "309_5     2.134014  0.192158  1.504230  ...  0.205604  0.129954  0.134762   \n",
       "\n",
       "            pS6_N   pCFOS_N     SYP_N  H3AcK18_N    EGR1_N  H3MeK4_N    CaNA_N  \n",
       "MouseID                                                                         \n",
       "309_1    0.106305  0.108336  0.427099   0.114783  0.131790  0.128186  1.675652  \n",
       "309_2    0.106592  0.104315  0.441581   0.111974  0.135103  0.131119  1.743610  \n",
       "309_3    0.108303  0.106219  0.435777   0.111883  0.133362  0.127431  1.926427  \n",
       "309_4    0.103184  0.111262  0.391691   0.130405  0.147444  0.146901  1.700563  \n",
       "309_5    0.104784  0.110694  0.434154   0.118481  0.140314  0.148380  1.839730  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "xnames = df1.columns[0: -4]\n",
    "X = df1.iloc[:, 0:-4]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test with 30% allocated for test.  You can use the train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO:\n",
    "Xtr, Xts, ytr, yts = train_test_split(X, y, random_state=1, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data with the `StandardScaler`.  Store the scaled values in `Xtr1` and `Xts1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO\n",
    "scaler = StandardScaler()\n",
    "Xtr1 = scaler.fit_transform(Xtr.values)\n",
    "Xts1 = scaler.transform(Xts.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `LogisticRegression` object `logreg` and `fit` on the scaled training data.  Set the regularization level to `C=1e5` and use the optimizer `solver=liblinear`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e5, solver='liblinear')\n",
    "logreg = logreg.fit(Xtr1, ytr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of the classifer on test data.  You should get around 94%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.44"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "from sklearn.metrics import accuracy_score\n",
    "yhat = logreg.predict(Xts1)\n",
    "accuracy = accuracy_score(yts, yhat)\n",
    "round(accuracy*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the weight vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a stem plot of the coefficients, `W` in the logistic regression model.  Jse the `plt.stem()` function with the `use_line_collection=True` option.  You can get the coefficients from `logreg.coef_`, but you will need to reshape this to a 1D array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StemContainer object of 3 artists>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "W = logreg.coef_.reshape(-1,)\n",
    "plt.stem(W, use_line_collection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that `W[i]` is very large for a few components `i`.  These are the genes that are likely to be most involved in Down's Syndrome.   Below we will use L1 regression to enforce sparsity.  Find the names of the genes for two components `i` where the magnitude of `W[i]` is largest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ITSN1_N', 'BRAF_N'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "W_sorted = sorted(abs(W))\n",
    "max_W = W_sorted[-2:]\n",
    "# get the i of two maximum weights\n",
    "i = []\n",
    "i.append(np.where(abs(W) == max_W[1])[0][0]) # the i of the largest gene \n",
    "i.append(np.where(abs(W) == max_W[0])[0][0]) # the i of the second largest gene\n",
    "\n",
    "# get two genes with highest magnitudes\n",
    "highest_genes = xnames[i]\n",
    "highest_genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "To obtain a slightly more accurate result, now perform 10-fold cross validation and measure the average precision, recall and f1-score.  Note, that in performing the cross-validation, you will want to randomly permute the test and training sets using the `shuffle` option.  In this data set, all the samples from each class are bunched together, so shuffling is essential.  Print the mean precision, recall and f1-score and error rate across all the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a funiction returns a different logistic regression model for each fold\n",
    "def logistic_with_kf(kf, indices):\n",
    "    \"\"\"\n",
    "    this function train logistic regression models on data splitted into 10 datasets and returns the classification\n",
    "    metrics the evaluate the models.\n",
    "    input:\n",
    "        kf: the splitter to folds\n",
    "        indices: indices to be splitted for filtering\n",
    "    output:\n",
    "        tuple(class_metrics, list_confus): a data frame of classification metrics for each model and \n",
    "        confusion matrix for each model and the list of all accuracies over each model\n",
    "    \"\"\"\n",
    "    list_metrics = []\n",
    "    list_confus = []\n",
    "    list_accurr = []\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    for trainI, testI in kf.split(indices): # extract indices of each fold for train and test\n",
    "        model = LogisticRegression()\n",
    "        # fitting the model on  training data of each fold\n",
    "        model = model.fit(X_scaled[trainI], y[trainI])  \n",
    "        y_pred = model.predict(X_scaled[testI])\n",
    "        # get classification metrics of each model\n",
    "        metrics = precision_recall_fscore_support(y[testI], y_pred) \n",
    "        # get the error rate using  (1 - accuracy_score function output)\n",
    "        error_rate = 1 - accuracy_score(y[testI], y_pred) \n",
    "        list_metrics.append([metrics[0][1], metrics[1][1], metrics[2][1], error_rate])\n",
    "        # append the confusion matrix for each model with normalized rows\n",
    "        list_confus.append(confusion_matrix(y[testI], y_pred, normalize='true'))\n",
    "        # append the accurrecy for each model\n",
    "        list_accurr.append(accuracy_score(y[testI], y_pred))\n",
    "    # return a data frame to store the metrics\n",
    "    class_metrics = pd.DataFrame(list_metrics, columns=['precision', 'recall', 'f-1 score', 'error rate'])    \n",
    "    return class_metrics, list_confus, list_accurr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision     0.980270\n",
       "recall        0.960885\n",
       "f-1 score     0.970324\n",
       "error rate    0.027778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold,shuffle=True)\n",
    "\n",
    "# TODO\n",
    "class_metrics = logistic_with_kf(kf, df1.index)[0]\n",
    "#get the average over 10 models\n",
    "class_metrics.mean() \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification\n",
    "\n",
    "Now use the response variable in `df1['class']`.  This has 8 possible classes.  Use the `np.unique` funtion as before to convert this to a vector `y` with values 0 to 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 7, 7], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "y = np.unique(df1['class'], return_inverse=True)[1]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a multi-class logistic model by creating a `LogisticRegression` object, `logreg` and then calling the `logreg.fit` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform 10-fold cross validation, and measure the confusion matrix `C` on the test data in each fold. You can use the `confustion_matrix` method in the `sklearn` package.  Add the confusion matrix counts across all folds and then normalize the rows of the confusion matrix so that they sum to one.  Thus, each element `C[i,j]` will represent the fraction of samples where `yhat==j` given `ytrue==i`.  Print the confusion matrix.  You can use the command\n",
    "\n",
    "    print(np.array_str(C, precision=4, suppress_small=True))\n",
    "    \n",
    "to create a nicely formatted print.  Also print the overall mean and SE of the test accuracy across the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# TODO\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold,shuffle=True)\n",
    "# get the confusion matrices and accuracies\n",
    "C, accurr = logistic_with_kf(kf, df1.index)[1:] \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.9    0.     0.     0.     0.1    0.     0.    ]\n",
      "  [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      " [[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      " [[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      " [[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      "  [0.0526 0.     0.     0.9474 0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      " [[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.0526 0.9474 0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      " [[0.9545 0.     0.     0.     0.0455 0.     0.     0.    ]\n",
      "  [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      " [[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.0667 0.9333 0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      "  [0.125  0.     0.     0.75   0.     0.     0.     0.125 ]\n",
      "  [0.     0.0588 0.     0.     0.9412 0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      " [[0.9231 0.0769 0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      " [[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      " [[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      "  [0.     0.     0.     0.     0.     0.     0.     1.    ]]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array_str(np.array(C), precision=4, suppress_small=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean over all the accurracies is : 0.99\n",
      " The SE over the all accurracies is : 0.00333\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print('The mean over all the accurracies is : {}\\n The SE over the all accurracies is : {}'\n",
    "      .format(round(np.mean(accurr), 2), \n",
    "      round(np.std(accurr)/ math.sqrt(nfold), 5)\n",
    "             )\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the logistic regression on the entire training data and get the weight coefficients.  This should be a 8 x 77 matrix.  Create a stem plot of the first row of this matrix to see the coefficients on each of the genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYRK1A_N</th>\n",
       "      <th>ITSN1_N</th>\n",
       "      <th>BDNF_N</th>\n",
       "      <th>NR1_N</th>\n",
       "      <th>NR2A_N</th>\n",
       "      <th>pAKT_N</th>\n",
       "      <th>pBRAF_N</th>\n",
       "      <th>pCAMKII_N</th>\n",
       "      <th>pCREB_N</th>\n",
       "      <th>pELK_N</th>\n",
       "      <th>...</th>\n",
       "      <th>SHH_N</th>\n",
       "      <th>BAD_N</th>\n",
       "      <th>BCL2_N</th>\n",
       "      <th>pS6_N</th>\n",
       "      <th>pCFOS_N</th>\n",
       "      <th>SYP_N</th>\n",
       "      <th>H3AcK18_N</th>\n",
       "      <th>EGR1_N</th>\n",
       "      <th>H3MeK4_N</th>\n",
       "      <th>CaNA_N</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MouseID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309_1</th>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.747193</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>2.816329</td>\n",
       "      <td>5.990152</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>0.177565</td>\n",
       "      <td>2.373744</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>1.750936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188852</td>\n",
       "      <td>0.122652</td>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.106305</td>\n",
       "      <td>0.108336</td>\n",
       "      <td>0.427099</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>0.131790</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>1.675652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_2</th>\n",
       "      <td>0.514617</td>\n",
       "      <td>0.689064</td>\n",
       "      <td>0.411770</td>\n",
       "      <td>2.789514</td>\n",
       "      <td>5.685038</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.172817</td>\n",
       "      <td>2.292150</td>\n",
       "      <td>0.226972</td>\n",
       "      <td>1.596377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200404</td>\n",
       "      <td>0.116682</td>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.106592</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.441581</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>1.743610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_3</th>\n",
       "      <td>0.509183</td>\n",
       "      <td>0.730247</td>\n",
       "      <td>0.418309</td>\n",
       "      <td>2.687201</td>\n",
       "      <td>5.622059</td>\n",
       "      <td>0.209011</td>\n",
       "      <td>0.175722</td>\n",
       "      <td>2.283337</td>\n",
       "      <td>0.230247</td>\n",
       "      <td>1.561316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193685</td>\n",
       "      <td>0.118508</td>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.108303</td>\n",
       "      <td>0.106219</td>\n",
       "      <td>0.435777</td>\n",
       "      <td>0.111883</td>\n",
       "      <td>0.133362</td>\n",
       "      <td>0.127431</td>\n",
       "      <td>1.926427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_4</th>\n",
       "      <td>0.442107</td>\n",
       "      <td>0.617076</td>\n",
       "      <td>0.358626</td>\n",
       "      <td>2.466947</td>\n",
       "      <td>4.979503</td>\n",
       "      <td>0.222886</td>\n",
       "      <td>0.176463</td>\n",
       "      <td>2.152301</td>\n",
       "      <td>0.207004</td>\n",
       "      <td>1.595086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.192112</td>\n",
       "      <td>0.132781</td>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.103184</td>\n",
       "      <td>0.111262</td>\n",
       "      <td>0.391691</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.147444</td>\n",
       "      <td>0.146901</td>\n",
       "      <td>1.700563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309_5</th>\n",
       "      <td>0.434940</td>\n",
       "      <td>0.617430</td>\n",
       "      <td>0.358802</td>\n",
       "      <td>2.365785</td>\n",
       "      <td>4.718679</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>0.173627</td>\n",
       "      <td>2.134014</td>\n",
       "      <td>0.192158</td>\n",
       "      <td>1.504230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205604</td>\n",
       "      <td>0.129954</td>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.104784</td>\n",
       "      <td>0.110694</td>\n",
       "      <td>0.434154</td>\n",
       "      <td>0.118481</td>\n",
       "      <td>0.140314</td>\n",
       "      <td>0.148380</td>\n",
       "      <td>1.839730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
       "MouseID                                                                         \n",
       "309_1    0.503644  0.747193  0.430175  2.816329  5.990152  0.218830  0.177565   \n",
       "309_2    0.514617  0.689064  0.411770  2.789514  5.685038  0.211636  0.172817   \n",
       "309_3    0.509183  0.730247  0.418309  2.687201  5.622059  0.209011  0.175722   \n",
       "309_4    0.442107  0.617076  0.358626  2.466947  4.979503  0.222886  0.176463   \n",
       "309_5    0.434940  0.617430  0.358802  2.365785  4.718679  0.213106  0.173627   \n",
       "\n",
       "         pCAMKII_N   pCREB_N    pELK_N  ...     SHH_N     BAD_N    BCL2_N  \\\n",
       "MouseID                                 ...                                 \n",
       "309_1     2.373744  0.232224  1.750936  ...  0.188852  0.122652  0.134762   \n",
       "309_2     2.292150  0.226972  1.596377  ...  0.200404  0.116682  0.134762   \n",
       "309_3     2.283337  0.230247  1.561316  ...  0.193685  0.118508  0.134762   \n",
       "309_4     2.152301  0.207004  1.595086  ...  0.192112  0.132781  0.134762   \n",
       "309_5     2.134014  0.192158  1.504230  ...  0.205604  0.129954  0.134762   \n",
       "\n",
       "            pS6_N   pCFOS_N     SYP_N  H3AcK18_N    EGR1_N  H3MeK4_N    CaNA_N  \n",
       "MouseID                                                                         \n",
       "309_1    0.106305  0.108336  0.427099   0.114783  0.131790  0.128186  1.675652  \n",
       "309_2    0.106592  0.104315  0.441581   0.111974  0.135103  0.131119  1.743610  \n",
       "309_3    0.108303  0.106219  0.435777   0.111883  0.133362  0.127431  1.926427  \n",
       "309_4    0.103184  0.111262  0.391691   0.130405  0.147444  0.146901  1.700563  \n",
       "309_5    0.104784  0.110694  0.434154   0.118481  0.140314  0.148380  1.839730  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 7, 7], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "Xtr, Xts, ytr, yts = train_test_split(X, y, random_state=1, test_size=0.3)\n",
    "model = LogisticRegression()\n",
    "model = model.fit(Xtr, ytr)\n",
    "\n",
    "weights = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.54708149e-01, -8.66100912e-01,  2.30516384e-01,\n",
       "         2.69683748e-01,  1.17187686e+00,  2.61250110e-01,\n",
       "         2.54288733e-01, -6.94854774e-01, -4.23234141e-01,\n",
       "        -7.52829827e-01,  1.76254229e+00,  8.01765771e-01,\n",
       "         4.88498819e-01,  2.25606042e-01,  7.65414767e-02,\n",
       "        -5.51517888e-01, -1.35522636e+00,  3.79031886e-01,\n",
       "         5.02934652e-01,  2.81980582e-01,  7.51606037e-01,\n",
       "        -1.42547729e-01, -1.02777130e-01, -4.58387689e-01,\n",
       "         1.18264830e+00,  1.47037497e+00,  4.08085375e-01,\n",
       "        -2.53840960e-01,  5.86914777e-01, -3.66561384e-02,\n",
       "        -8.94526570e-01, -1.41518423e+00, -2.19197010e+00,\n",
       "         8.74576811e-01,  9.56962014e-01,  4.63059739e-01,\n",
       "        -6.46167273e-01,  9.51779741e-02,  8.72928198e-01,\n",
       "         2.86691746e-01,  3.82433129e-02, -8.52304236e-01,\n",
       "         3.67321944e-01, -4.03320416e-01, -1.18154385e+00,\n",
       "        -2.43989344e-01, -7.30193236e-02, -2.00863015e-01,\n",
       "        -2.37528020e-01,  3.89118418e-02, -6.05366875e-01,\n",
       "        -3.34222845e-01, -6.11167689e-01,  8.73094346e-02,\n",
       "         1.04651215e-01,  5.51090791e-01, -6.92954308e-02,\n",
       "        -1.98975723e-01,  4.33282462e-01, -7.92901530e-02,\n",
       "         9.93608936e-01,  2.35978354e-01,  1.86012021e-01,\n",
       "        -9.70289902e-01, -1.17403337e-01,  7.40468264e-01,\n",
       "         1.31278108e+00,  3.74185769e-01,  8.85407466e-02,\n",
       "        -1.13379793e-01,  8.73094346e-02, -2.47523131e-01,\n",
       "         8.21966602e-01, -2.46834875e-01, -2.12717555e-01,\n",
       "        -1.20740829e-01,  1.48003648e-01],\n",
       "       [ 1.77805891e-01, -4.31397862e-01, -9.89988596e-02,\n",
       "         3.65543022e-01,  5.52371431e-01, -2.15895766e-01,\n",
       "        -1.95457336e-01, -6.52222947e-01,  1.29619444e-01,\n",
       "         1.10521902e+00,  5.25237940e-01, -8.11083873e-01,\n",
       "         1.95664232e-02, -1.19193119e-01,  1.60149100e-01,\n",
       "         1.30547958e-01, -8.19469615e-01,  3.16943770e+00,\n",
       "        -2.10468918e-01, -1.06838864e+00,  1.29228681e+00,\n",
       "         6.94936204e-01,  8.37902439e-02, -5.10500319e-01,\n",
       "         7.86096552e-01, -6.80098088e-01, -2.76573984e-01,\n",
       "         1.61922486e-01, -1.53657697e+00,  2.92395615e-01,\n",
       "        -1.46479861e+00, -5.74876905e-01, -9.66814806e-01,\n",
       "        -2.76961538e-01, -2.03098223e-01,  5.46823869e-03,\n",
       "        -5.56989663e-01,  4.50828539e-01, -1.52096870e-01,\n",
       "         8.55821313e-01,  4.17910157e-01, -5.49977556e-02,\n",
       "        -2.40175890e-01,  1.68243687e-01, -1.57169635e-01,\n",
       "         4.72082606e-01, -7.27952854e-01,  3.68559550e-01,\n",
       "        -2.98739744e-01,  7.16027037e-02, -6.01046036e-01,\n",
       "         3.44615504e-01,  4.09131167e-01, -1.16158313e-02,\n",
       "        -9.26448299e-02, -6.31618896e-01, -7.23724918e-01,\n",
       "         3.47856666e-01,  3.01695943e-01,  1.61465746e-01,\n",
       "        -1.13141705e+00, -6.41084841e-02,  5.76635910e-01,\n",
       "        -1.20243118e+00,  2.53842866e-01, -2.10333285e+00,\n",
       "        -4.45622378e-01, -6.17661266e-02,  3.10561539e-02,\n",
       "         8.20725840e-02, -1.16158313e-02,  2.66814359e-01,\n",
       "         1.79768907e-01,  4.24980032e-01,  2.65684814e-01,\n",
       "         2.31704871e-01,  2.44114602e+00],\n",
       "       [-1.20428347e+00, -1.69834087e+00, -9.74180780e-02,\n",
       "        -7.75136053e-01, -9.02185085e-01, -2.11547278e-01,\n",
       "         3.67153336e-02,  1.74750781e+00, -5.66312017e-02,\n",
       "         1.31530034e-01, -5.69476102e-01,  1.75778841e-01,\n",
       "        -1.31322011e-01, -7.48281954e-02,  1.72596096e-01,\n",
       "         2.71281535e+00,  6.80495525e-02, -1.78067249e+00,\n",
       "        -2.08947367e-02, -4.64214912e-01, -7.74263618e-01,\n",
       "        -2.30651486e-01, -3.31861214e-02,  6.88148540e-01,\n",
       "         5.10133379e-02,  3.06250071e-01, -9.04057970e-02,\n",
       "        -1.10172102e-01, -9.30702533e-01, -6.71802109e-02,\n",
       "        -1.21818270e+00, -8.78248125e-01,  6.44622675e-01,\n",
       "         4.76488281e-02,  5.52116619e-01,  5.16652660e-01,\n",
       "         2.43911657e-01,  4.88039519e-01, -4.91460175e-04,\n",
       "         9.37131210e-02,  2.24109844e-01, -2.42367682e-01,\n",
       "         2.18417118e-01,  1.79944891e-01,  1.85331816e+00,\n",
       "        -9.98578596e-02,  1.18618004e-01, -9.46833301e-02,\n",
       "        -1.16932005e+00, -1.87795527e+00, -9.39459196e-01,\n",
       "         1.85640721e-01,  2.62268930e-01, -1.19814365e-02,\n",
       "        -7.93104771e-02,  3.74552905e-02, -2.87708374e-01,\n",
       "        -5.68018899e-02,  3.28308438e-01,  2.33522026e-01,\n",
       "         2.65657360e-01, -2.38747835e-01, -1.11952602e-01,\n",
       "         5.16380072e-01,  3.08739268e-02,  1.20045387e+00,\n",
       "         1.64511233e-01, -1.47987106e-01,  1.70264043e-01,\n",
       "         1.80412764e-01, -1.19814365e-02,  1.75031247e-01,\n",
       "         7.64287127e-01,  2.38703777e-01,  3.33880492e-01,\n",
       "         2.51118098e-02, -1.93795236e+00],\n",
       "       [-1.14010115e+00, -2.20204665e+00,  7.80838047e-02,\n",
       "         1.64168139e+00,  1.02813734e+00, -3.38814562e-01,\n",
       "        -1.57009344e-01, -3.13278207e-01, -2.17018127e-01,\n",
       "        -2.76296325e-01, -1.51828649e+00, -4.99467043e-01,\n",
       "        -2.08960902e-01, -3.89532899e-01,  6.40753153e-01,\n",
       "        -2.69200261e-01,  7.49121901e-01,  1.81127346e-01,\n",
       "        -6.92780298e-02,  1.35435159e+00, -6.77606222e-01,\n",
       "        -2.35808541e-01, -1.26782490e-01,  1.39915695e+00,\n",
       "        -1.73954868e+00, -1.75257086e+00, -1.43423505e-01,\n",
       "        -1.14231397e-01, -1.43279232e-01, -1.90192586e-01,\n",
       "        -8.24850262e-01,  5.72722247e-02,  1.56730470e+00,\n",
       "         5.79853156e-01,  5.38099744e-01, -3.77345834e-01,\n",
       "        -1.42558193e+00, -2.94258301e-01,  2.48340741e-01,\n",
       "        -1.36862956e+00, -5.78621604e-01, -9.98421913e-01,\n",
       "         3.51624077e-01, -7.85559891e-02, -1.16607346e+00,\n",
       "        -1.50876446e-01, -1.07467863e+00, -1.96823644e-01,\n",
       "        -8.69527278e-01,  6.63506506e-01,  4.27394430e-01,\n",
       "        -2.59060753e-01, -5.92371525e-02,  1.32755602e-01,\n",
       "         6.94589452e-02,  2.10024444e-01,  3.71944980e-01,\n",
       "        -4.00963328e-02,  3.34754602e-01,  8.51235493e-02,\n",
       "         1.15994443e+00,  2.39538555e-01, -1.13065288e+00,\n",
       "         1.85060996e+00,  1.41369085e-01, -9.78450676e-01,\n",
       "         1.61659038e-01,  5.50037997e-01, -1.14779579e-02,\n",
       "        -2.52634068e-02,  1.32755602e-01,  1.36916214e-01,\n",
       "         4.58821115e-01, -5.35443741e-01,  2.51706335e-01,\n",
       "        -1.52500988e-01,  2.33901509e-01],\n",
       "       [ 1.47330339e+00,  1.89576880e+00,  2.67477617e-01,\n",
       "         6.16447219e-03,  2.60306336e-02, -2.71139853e-01,\n",
       "         3.94463515e-03,  4.35346696e-02,  1.37658912e-03,\n",
       "        -5.77987235e-01,  1.13315400e+00, -4.85333508e-01,\n",
       "         1.09918012e-01, -3.19553271e-01,  7.28976456e-02,\n",
       "        -1.20975495e+00,  6.22910102e-01,  8.37655158e-01,\n",
       "         1.76033368e-01, -8.82071299e-01,  4.01165893e-02,\n",
       "        -8.31754320e-01,  1.07464689e-01,  3.93410395e-01,\n",
       "        -2.32474450e+00,  4.31186439e-01,  7.40086102e-02,\n",
       "        -4.62797633e-02,  4.38540156e-01, -1.85513892e-01,\n",
       "         1.59400479e+00,  1.20640282e+00, -1.43717152e+00,\n",
       "        -4.40513660e-01, -3.75621675e-01, -5.01395673e-01,\n",
       "         7.69886947e-01, -2.35541966e-01, -7.51858384e-02,\n",
       "        -4.87812279e-01, -2.51079052e-01,  3.49899935e-01,\n",
       "         6.49378901e-01, -2.05319562e-01, -7.48349619e-03,\n",
       "        -5.64279259e-02, -1.27835091e+00, -1.63579661e-01,\n",
       "        -2.64515020e-01, -1.06291137e+00,  2.69482577e-01,\n",
       "        -2.10264689e-01, -3.06222189e-02, -1.43325296e-01,\n",
       "        -7.57741566e-02,  1.39888086e-01, -3.09049731e-01,\n",
       "        -1.89123366e-01,  2.22537065e-01,  1.42721226e-01,\n",
       "         4.13297207e-01, -1.96727238e-01,  1.07030475e-01,\n",
       "         7.57311355e-01, -3.43558073e-01, -1.51548977e+00,\n",
       "        -5.13901632e-02, -2.83621480e-01, -3.81520820e-02,\n",
       "         1.07325776e-01, -1.43325296e-01,  1.04614215e-01,\n",
       "        -3.41421298e-01, -1.88782348e-01, -5.78263168e-02,\n",
       "        -2.24034668e-01,  3.23706067e+00],\n",
       "       [ 5.08209602e-01,  1.50368819e+00, -3.19876437e-01,\n",
       "        -1.18180278e+00, -1.40563933e+00,  1.32135643e-01,\n",
       "        -1.17634571e-01, -1.43853759e+00,  1.87342574e-01,\n",
       "         9.11453938e-01,  8.39834632e-01,  4.13374906e-01,\n",
       "        -1.14964045e-01, -5.28345676e-02, -5.49269026e-01,\n",
       "         7.07463644e-01,  1.09905687e+00,  1.50748851e+00,\n",
       "        -1.59219303e-01,  1.56373851e-01,  4.16034070e-02,\n",
       "         3.02908002e-01, -1.47852457e-01, -4.70719807e-02,\n",
       "         2.10629097e+00,  2.92503273e-01, -1.44289509e-02,\n",
       "        -1.22547588e-01,  6.11603331e-01, -3.37787170e-02,\n",
       "         1.18518472e+00, -1.03376274e+00, -1.11466976e+00,\n",
       "        -5.65290933e-01, -1.27605791e+00, -8.15744087e-01,\n",
       "         4.56643024e-01, -4.81167424e-01, -1.11679892e+00,\n",
       "         3.13565598e-01, -4.00380080e-01,  3.82409084e-01,\n",
       "        -1.42286986e+00,  5.21336010e-01,  1.35177165e+00,\n",
       "         4.10196602e-02,  1.00299227e+00,  2.44313965e-01,\n",
       "         2.35572565e+00,  7.98616173e-01,  3.92868381e-01,\n",
       "         2.09190409e-01,  7.99929088e-02, -9.15049059e-02,\n",
       "        -2.46205429e-02, -3.08369593e-01,  3.73836875e-01,\n",
       "         2.21702177e-01, -6.55834148e-01, -1.96563863e-01,\n",
       "        -6.15458816e-01,  8.26768033e-02, -1.15463610e+00,\n",
       "         1.20444812e-01,  7.61693065e-02,  1.47957702e+00,\n",
       "        -1.22072781e+00, -4.77977620e-02, -5.51839185e-02,\n",
       "         3.94043342e-02, -9.15049059e-02, -1.23003272e-01,\n",
       "        -4.93119377e-01, -4.12767474e-02, -1.65354629e-01,\n",
       "        -3.08889692e-02, -2.43433329e-01],\n",
       "       [ 1.91064131e-01,  1.79011738e+00, -1.16670588e-01,\n",
       "        -3.26079643e-01,  3.44908721e-01,  6.23749897e-01,\n",
       "         1.96927053e-01,  6.79853936e-01,  2.28856975e-01,\n",
       "        -1.70893014e-01, -1.01158017e+00,  4.34033946e-01,\n",
       "        -5.51609257e-02,  5.89541390e-01, -4.56031048e-01,\n",
       "        -5.18585023e-01,  9.58338079e-01, -2.41484954e+00,\n",
       "        -1.74844415e-01,  5.20332519e-01,  3.25238761e-02,\n",
       "         5.81095716e-01,  1.22772164e-01, -1.76951042e+00,\n",
       "        -9.65196139e-01,  4.06536540e-01,  1.41635347e-01,\n",
       "         3.08192548e-01,  1.13300120e+00,  2.83271539e-01,\n",
       "         1.09053952e+00,  5.79157755e-01,  2.13735695e+00,\n",
       "        -2.61287810e-01, -2.28588690e-02,  1.01725559e+00,\n",
       "         7.97806008e-01, -2.27716650e-01,  1.34593496e-01,\n",
       "         2.88357350e-03,  2.14640648e-01,  5.44084051e-01,\n",
       "        -1.03908041e+00, -1.80707444e-01,  3.11719100e-02,\n",
       "        -1.70643717e-01, -1.11074718e+00, -7.28169505e-02,\n",
       "         4.55360978e-02,  1.29932436e+00,  1.16913892e+00,\n",
       "        -1.93824350e-01, -7.04095404e-02,  1.39820854e-01,\n",
       "         1.59758899e-01,  3.44060785e-02,  2.93915498e-01,\n",
       "        -1.40984705e-01, -7.38248828e-01, -3.55528627e-01,\n",
       "        -2.87086889e-01, -2.79599286e-01,  1.02574051e+00,\n",
       "         3.75005756e-01,  2.06534280e-02,  1.43989594e+00,\n",
       "        -3.26412382e-01, -2.83346612e-01, -3.84343453e-01,\n",
       "        -2.82685054e-01,  1.39820854e-01, -3.84342485e-01,\n",
       "        -9.12205835e-01,  3.87702296e-01, -3.36025572e-01,\n",
       "         1.30186934e-01, -2.50524779e+00],\n",
       "       [-2.60706548e-01,  8.31192600e-03,  5.68861572e-02,\n",
       "        -5.41501159e-05, -8.15500572e-01,  2.02618087e-02,\n",
       "        -2.17745027e-02,  6.27997106e-01,  1.49687887e-01,\n",
       "        -3.70196585e-01, -1.16142609e+00, -2.90690404e-02,\n",
       "        -1.07575369e-01,  1.40794621e-01, -1.17637397e-01,\n",
       "        -1.00176883e+00, -1.32278053e+00, -1.87921856e+00,\n",
       "        -4.42626169e-02,  1.01636306e-01, -7.06266883e-01,\n",
       "        -1.38177847e-01,  9.65711031e-02,  3.04754524e-01,\n",
       "         9.03440157e-01, -4.74182348e-01, -9.88970964e-02,\n",
       "         1.76956777e-01, -1.59500722e-01, -6.23456097e-02,\n",
       "         5.32629101e-01,  2.05923920e+00,  1.36134186e+00,\n",
       "         4.19751453e-02, -1.69541700e-01, -3.07950637e-01,\n",
       "         3.60491226e-01,  2.04638308e-01,  8.87106512e-02,\n",
       "         3.03766488e-01,  3.35176774e-01,  8.71698516e-01,\n",
       "         1.11538412e+00, -1.62117765e-03, -7.23991283e-01,\n",
       "         2.08693027e-01,  3.14313862e+00,  1.15893085e-01,\n",
       "         4.38368363e-01,  6.89050609e-02, -1.13012204e-01,\n",
       "         2.57926004e-01,  2.00435946e-02, -1.01458421e-01,\n",
       "        -6.15190520e-02, -3.28762009e-02,  3.50081101e-01,\n",
       "         5.64231731e-02, -2.26495533e-01,  8.55009504e-03,\n",
       "        -7.98545178e-01,  2.20989130e-01,  5.01822670e-01,\n",
       "        -1.44703087e+00, -6.19472022e-02, -2.63121801e-01,\n",
       "         4.05201377e-01, -9.97046796e-02,  1.99296468e-01,\n",
       "         1.21127945e-02, -1.01458421e-01,  7.14928525e-02,\n",
       "        -4.78097242e-01, -3.90483926e-02, -7.93475697e-02,\n",
       "         1.41161840e-01, -1.37347837e+00]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W = weights[0].reshape(-1,)\n",
    "plt.stem(W, use_line_collection=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## L1-Regularization\n",
    "\n",
    "This section is bonus.\n",
    "\n",
    "In most genetic problems, only a limited number of the tested genes are likely influence any particular attribute.  Hence, we would expect that the weight coefficients in the logistic regression model should be sparse.  That is, they should be zero on any gene that plays no role in the particular attribute of interest.  Genetic analysis commonly imposes sparsity by adding an l1-penalty term.  Read the `sklearn` [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) on the `LogisticRegression` class to see how to set the l1-penalty and the inverse regularization strength, `C`.\n",
    "\n",
    "Using the model selection strategies from the [housing demo](../unit05_lasso/demo2_housing.ipynb), use K-fold cross validation to select an appropriate inverse regularization strength.  \n",
    "* Use 10-fold cross validation \n",
    "* You should select around 20 values of `C`.  It is up to you find a good range.\n",
    "* Make appropriate plots and print out to display your results\n",
    "* How does the accuracy compare to the accuracy achieved without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
